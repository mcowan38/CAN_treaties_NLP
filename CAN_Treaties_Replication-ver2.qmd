---
title: "Spirling (2012) Treaties Replication - Methods"
author: "Mike Cowan & Patrick Schnurbusch"
toc: true            # Enable the table of contents
toc-location: left   # Location of the TOC (can also be "right")
toc-floating: true   # Make the TOC float as you scroll
format: 
  html:
    theme: cosmo     # Choose a theme, if desired
    toc: true
    toc-depth: 3
    mainfont: Arial
    code-fold: true
    embed-resources: true
    df-print: paged
editor: visual
---

# Canadian KPCA Results{.underline}

```{r libraries_dependencies, include=FALSE}
# Generate KPCA for Time Trends + PCA, Correlations, and Random Forests
# Load packages:
library(tidyverse) # for data manipulation 
library(plotly) # for interactive graphs 
library(tm)
library(kernlab)
library(SnowballC) # for Similarity Matrix calculations
library(randomForest) # for rand forest 
library(xgboost) # for xgb 
library(caret)
library(stringr) # for string manipulation 
library(DT) # for datatables 


# change global options 
knitr::opts_chunk$set(
  echo = TRUE,            # show code by default
  message = FALSE,        # suppress messages
  warning = FALSE,        # suppress warnings
  fig.width = 6,          # default figure width
  fig.height = 4,         # default figure height
  fig.align = 'center',   # center align figures
  dpi = 300               # figure resolution for high quality
)
```

## Processing Corpus

-   VCorpus establishes our Treaty Corpus (rather than "Corpus" in Spirling's original code).

-   Alternatively, Corpus defaults to a PCorpus, which employs lazy loading (utilizes memory as needed). This method is unusable (database issues).

```{r read_data}
# VCorpus adjustment:
treatiesDT <-
  VCorpus(
    DirSource("./00_data/treaties_modified_CAN/Douglas Treaties/"),
    readerControl = list(
      reader = readPlain,
      language = "en",
      load = F
    )
  )

treatiesPF <-
  VCorpus(
    DirSource(
      "./00_data/treaties_modified_CAN/Peace and Friendship Treaties/"),
    readerControl = list(
      reader = readPlain,
      language = "en",
      load = F
    )
  )

treatiesRT <-
  VCorpus(
    DirSource("./00_data/treaties_modified_CAN/Robinson Treaties/"),
    readerControl = list(
      reader = readPlain,
      language = "en",
      load = F
    )
  )

treatiesNT <-
  VCorpus(
    DirSource("./00_data/treaties_modified_CAN/The Numbered Treaties/"),
    readerControl = list(
      reader = readPlain,
      language = "en",
      load = F
    )
  )

treatiesTPN <-
  VCorpus(
    DirSource(
      "./00_data/treaties_modified_CAN/Treaties of Peace and Neutrality/"),
    readerControl = list(
      reader = readPlain,
      language = "en",
      load = F
    )
  )

treatiesUCLS <-
  VCorpus(
    DirSource(
      "./00_data/treaties_modified_CAN/Upper Canada Land Surrenders/"),
    readerControl = list(
      reader = readPlain,
      language = "en",
      load = F
    )
  )

treatiesRP <-
  VCorpus(
    DirSource("./00_data/treaties_modified_CAN/Royal Proclamation/"),
    readerControl = list(
      reader = readPlain,
      language = "en",
      load = F
    )
  )

treatiesWT <-
  VCorpus(
    DirSource("./00_data/treaties_modified_CAN/Williams Treaties/"),
    readerControl = list(
      reader = readPlain,
      language = "en",
      load = F
    )
  )
```

-   Here, **FULL_corp** becomes our original, unaltered corpus database for KPCA and search functionality.
-   **CAN_corp** is used for analysis.
    -   **Note:** here is where we can think about removing treaty-sets collectively (e.g., the Douglas Treaties – treatiesDT).

```{r create_text_corpora, include=FALSE}
# seed for reproducibility:
set.seed(38)

# Generate FULL_corp:
FULL_corp <-
  c(
    treatiesDT,
    treatiesPF,
    treatiesRT,
    treatiesNT,
    treatiesRP,
    treatiesTPN,
    treatiesUCLS,
    treatiesWT
  )

FULL_corp

# Verify sample of the unprocessed text:
inspect(FULL_corp[1:5])  # Inspect the first 5 documents
```

# Pre-Processing

-   Converting the VCorpus to a character vector allows the string kernel to process the text data directly.

-   Proceed with analysis WITHOUT stems first (for KPCA).

```{r convert_vcorpus}
# Minimal preprocessing to remove non-textual elements and normalize:
FULL_corp <- tm_map(FULL_corp, content_transformer(function(x) {
  x <- gsub("http[s]?://\\S+", "", x) # Remove URLs
  x <-
    iconv(x, "latin1", "ASCII", sub = "") # Normalize encoding if needed
  return(x)
}))
```

-   Convert to lower case, remove punctuation, remove stop words, and stem.


```{r clean_data}
# Convert to lower case
CAN_corp <- tm_map(FULL_corp, content_transformer(tolower))

# Remove punctuation
CAN_corp <- tm_map(CAN_corp, removePunctuation)

# Remove English stop words
CAN_corp <- tm_map(CAN_corp, removeWords, stopwords("en"))

# Stem the words
CAN_corp <- tm_map(CAN_corp, stemDocument)

# Verify sample of the processed text:
# inspect(CAN_corp[1:5])
```

## **String Kernels**

### 1. Minimal Preprocessing

-   **Preserve Character of Text**: For string kernels, it's beneficial to retain the original character of the text as much as possible.

    -   This includes maintaining the original casing, punctuation, and possibly even misspellings or idiosyncrasies in the text.

    -   These elements can contribute to the distinctive substrings (consecutive characters) that the kernel will analyze.

### 2. Avoid Stemming

-   **Retain Word Forms**: Stemming reduces words to their root forms, which can diminish the lexical diversity that a string kernel might exploit to identify subtle textual similarities or differences.

    -   Avoid stemming unless it's necessary for other parts of your analysis where you need normalized word forms.

### 3. Cleaning Specifics

-   **Remove Non-textual Elements**: Clean the text from non-textual elements such as URLs, email addresses, or any metadata that might skew the analysis.

-   **Unicode Normalization**: If working with diverse languages or fonts, normalize text to a consistent Unicode format to avoid discrepancies due to encoding variations.

### 4. Language-Specific Stopwords

-   **Selective Use of Stopwords**: While Spirling might suggest keeping most of the text intact, removing extremely common stopwords could still be beneficial to reduce noise in the data. However, this should be done selectively to avoid losing meaningful textual context.

### 5. Handling Special Characters

-   **Special Characters and Punctuation**: In some cases, especially when analyzing legal or formal texts, punctuation such as commas, semicolons, or quotation marks could carry semantic weight.
    -   Decide based on the content type whether to retain these elements.

### 6. Error Handling

-   **Error and Anomaly Detection**: Check for anomalies or errors in the text that could significantly impact the analysis, such as corrupted text sections or placeholders from text extraction processes, and clean these appropriately.

## KPCA – 1, 2, & 10 Components

### **Explanation**

-   **Kernel PCA** **(KPCA)** extends the basic idea of Principal Component Analysis (PCA), which is used to reduce the dimensionality of large data sets – by simplifying them into principal components that capture the most important information.

    1.  **Dealing with Non-Linearity**: Traditional PCA works well with linear relationships, but many real-world data sets – including textual data – exhibit non-linear structures.

        -   KPCA uses kernel functions to project your data into a higher-dimensional space where these non-linear relationships can be linearly separated – potentially uncovering patterns PCA can miss.

    2.  **Major Patterns**: KPCA aims to identify the underlying patterns or trends in the treaty texts – such as themes or recurring issues – by transforming the text data into principal components – new variables that represent significant underlying trends in the data.

    3.  **Reduction and Visualization**: KPCA reduces the complexity of the data, making it easier to analyze and visualize.

        -   e.g., You might use it to see which themes are most prevalent across different treaties or to understand how certain concepts or topics cluster together.

    4.  **Analysis**: The kernel trick allows you to handle text data – typically hard to manage with linear methods – by measuring similarities (or distances) based on the treaties' language and content.

## Similarity Matrix

-   The similarity matrix method got us to the KPCA, but we had over done the cleaning – via stemming, removing punctuation and white space, etc.

    -   **Type**: The `type="string"` parameter specifies that the kernel should treat the input as strings. This is important because it indicates that the kernel will be analyzing text data, rather than numerical data.
    -   **Length**: The `length=5` parameter refers to the length of **substrings** (also called **n-grams** when discussing text) that the kernel considers when comparing two documents.
    -   In simple terms, this means that the kernel is looking at **how many sequences of 5 consecutive characters** **(n-grams of length 5) are common between any two pieces of text.**
    
```{r make_similarity_matrix}
# Commented out for testing 
# # Convert to character:
# FULL_corp <- sapply(FULL_corp, as.character)
# 
# # Define the string kernel:
# stringkern <- stringdot(type = "string", length = 5)
# 
# # Spirling's Method - KPC1:
# KPC1 <- kpca(
#   FULL_corp,
#   kernel = stringkern,
#   kpar = list(sigma = 0.1),
#   features = 1,
#   th = 1e-4,
#   na.action = na.omit
# )
# 
# # Spirling's Method - KPC2:
# KPC2 <- kpca(
#   FULL_corp,
#   kernel = stringkern,
#   kpar = list(sigma = 0.1),
#   features = 2,
#   th = 1e-4,
#   na.action = na.omit
# )
# 
# # Spirling's Method - KPC10:
# KPC10 <- kpca(
#   FULL_corp,
#   kernel = stringkern,
#   kpar = list(sigma = 0.1),
#   features = 10,
#   th = 1e-4,
#   na.action = na.omit
# )

# Save Results:
# save(KPC1, file = "./00_scripts/01_CAN/CAN_KPC1.rdata")
# save(KPC2, file = "./00_scripts/01_CAN/CAN_KPC2.rdata")
# save(KPC10, file = "./00_scripts/01_CAN/CAN_KPC10.rdata")
```
    
```{r load_similarity_matrix}
# load similarity matrix results
load("./00_scripts/01_CAN/CAN_KPC1_douglas.rdata")
load("./00_scripts/01_CAN/CAN_KPC2_douglas.rdata")
load("./00_scripts/01_CAN/CAN_KPC10_douglas.rdata")
```

  
## **Scree Plot by Eigenvalues**

-   Here we're looking for the elbow (arguably occurs at 1 or 2 eigenvalues).

    -   By **eiganvalues**: indicates the amount of variance in the data that is explained by its corresponding principal component.

    -   Higher eigenvalues mean that the principal component captures more variance from the data.

-   We had to change up how many Principal Components were being detected so we could get a graph out of this (here we look at 10).  
  

```{r new_scree_plot}
eigenvalues <- KPC10@eig

# Create a df for plotting:
scree_data <- data.frame(
  Principal_Component = seq_along(eigenvalues),
  Eigenvalue = eigenvalues
)

# creating a margins list for plotting
margin_list <- list(autoexpand = FALSE,
               l = 100,
               r = 100,
               t = 110)

plot_ly(
  data = scree_data, 
  x = ~Principal_Component, 
  y = ~Eigenvalue, 
  type = 'scatter', 
  mode = 'lines+markers',
  text = ~paste0("Component: ", Principal_Component, "\nEigenvalue: ", round(Eigenvalue, digits = 3)),
  hoverinfo = 'text', 
  marker = list(size = 9, color = 'red'),    # Black markers
  line = list(color = '#c3c9d2', width = 2.5)        # Blue lines
) %>% 
  # Add title and axis labels with clear titles and units
  layout(
    #title = "<b>Scree Plot - KPCA Results</b>\n10 Components",        # Chart title
    title = list(
      text = paste0("<b>Figure X</b><br><i>KPCA Results - 10 Components</i>"),
      x = 0.1, 
      y = -1,
      xanchor = "left", 
      yanchor = "top", 
      font = list(size = 16)
    ),
    xaxis = list(title = "Principal Components",       # X-axis label
                 type = "linear",                      # Linear scale for X-axis
                 tickformat = ",.0f",                  # Thousands separator for readability
                 titlefont = list(size = 14)),         # Axis label font size
    yaxis = list(title = "Eigenvalue",                 # Y-axis label
                 type = "linear",                      # Linear scale for Y-axis
                 titlefont = list(size = 14)),         # Axis label font size
    
    hovermode = "x unified",  # Unified hover mode removes individual marker dots
    # Font styling for consistency with APA or academic standards
    font = list(family = "Arial", size = 12, color = "black"), # Set global font style
    
    # Set Margins 
    margin = list(l = 100, r = 100, t = 150, b = 100),
    # Set light gray grid lines for clarity without clutter
    xaxis = list(showgrid = TRUE, gridcolor = 'lightgray'),
    yaxis = list(showgrid = TRUE, gridcolor = 'lightgray')
  ) %>% 
  config(displaylogo = FALSE)
```

## Stemming Tests

-   Now we investigate the **KPCA Loadings, Correlations,** and **word importance via Random Forest.**

-   The output here is to a **.csv** file that let's us scroll through every word/stem in the document and see how they relate to our Principal Component – whatever it may be.

```{r stem_texts}
# Stemming:
dtm_1 <- DocumentTermMatrix(
  CAN_corp,
  control = list(
    # [Alternative processsing]:
    # Stemming using the Porter algorithm:
    # stemming = TRUE,
    
    # Removes punctuation:
    # removePunctuation = TRUE,
    
    # Removes stopwords (default is English):
    # stopwords = TRUE,
    
    # Applies TF-IDF weighting:
    weighting = weightTfIdf,
    # This mathematicizes importance of terms in document.
    
    # Remove numbers to avoid confusion with identifiers:
    removeNumbers = TRUE,
    
    # Keeps terms only present in at least 90% of documents:
    removeSparseTerms = 0.90
  )
)

# Extract PC1 for TDM:
# Extract the 1st Principal Component scores:
pc1_scores <-
  KPC1@rotated[, 1] # Adjusting this line to correctly access the PCA

# Linear detrending of the PCA scores for localized shifts in language:
pc1_scores <-resid(lm(pc1_scores ~ seq_along(pc1_scores)))

#pc1_scores

# Extract PC2 for TDM:
# Extract the second principal component:
pc2_scores <- KPC2@rotated[, 2] # Adjusting this line to correctly access the PCA

# Linear detrending of the PCA scores for localized shifts in language:
pc2_scores <- resid(lm(pc2_scores ~ seq_along(pc2_scores)))

#pc2_scores
```


## Correlation Results 

### Principle Component 1

-   Clarify if detrended stuff needs to come from KPCA or from the TDM PC1.

```{r get_correlations}
# Convert DTM to matrix and get term frequencies:
term_matrix <- as.matrix(dtm_1)
term_frequencies <-
  colSums(term_matrix > 0) # Using binary presence/absence for correlation

# Check if dimensions match:
if (length(pc1_scores) != nrow(term_matrix)) {
  stop("Mismatch in number of documents and PCA scores")
}

# Calculate correlations for each term:
# We use this to compliment Random Forest plot (Table 1, p. 91).
correlations <- sapply(1:ncol(term_matrix), function(i) {
  cor(term_matrix[, i], pc1_scores, use = "complete.obs", method = "pearson")
})

# Correctly handling NA values in correlations (if any):
if (any(is.na(correlations))) {
  correlations[is.na(correlations)] <-
    0  # Optionally handle NA values
}

# Results:
terms <- colnames(term_matrix)
results_df <- data.frame(Term = terms,
                         Frequency = term_frequencies,
                         Correlation = correlations)

# This orders the output in the .csv by from most positive to most negative:
results_df <- results_df[order(-results_df$Correlation), ]

# Output results to a .csv file:
write.csv(
  results_df,
  "./00_documents/visuals/correlations_PC1.csv",
  row.names = FALSE
)

# display results using datatable 
results_df %>% 
  datatable()
```

### Principle Component 2

```{r compute_pc2}
# Convert DTM to matrix and get term frequencies:
term_matrix <- as.matrix(dtm_1)

# Calculate term frequencies (using binary presence/absence for correlation):
term_frequencies <- colSums(term_matrix > 0)

# Check if dimensions match:
if (length(pc2_scores) != nrow(term_matrix)) {
  stop("Mismatch in number of documents and PCA scores")
}

# Calculate correlations for each term with the 2nd principal component:
correlations_pc2 <- sapply(1:ncol(term_matrix), function(i) {
  cor(term_matrix[, i], pc2_scores, use = "complete.obs", method = "pearson")
})

# Correctly handle NA values in correlations (if any):
if (any(is.na(correlations_pc2))) {
  correlations_pc2[is.na(correlations_pc2)] <-
    0  # Optionally handle NA values
}

# Make a dataframe to view results:
terms <- colnames(term_matrix)
results_df_pc2 <- data.frame(Term = terms,
                             Frequency = term_frequencies,
                             Correlation = correlations_pc2)

# Order the output by absolute correlation value (from high to low):
results_df_pc2 <-
  results_df_pc2[order(-results_df_pc2$Correlation), ]

# Output results to a .csv file:
write.csv(
  results_df_pc2,
  "./00_documents/visuals/correlations_PC2.csv",
  row.names = FALSE
)

# display results using datatable 
results_df_pc2 %>% 
  datatable()
```

## Random Forest Results 

**Why use both approaches** (1. KPCA & 2. PCA via TDM with Cor & RF)?

-   **Complementarity**: Kernel PCA and traditional PCA serve complementary roles. Kernel PCA can capture nonlinear relationships in high-dimensional data, making it suitable for complex text data structures. However, its results might be more abstract and harder to interpret directly in terms of original features (words). On the other hand, traditional PCA with a TDM provides a more interpretable model, as it directly relates to the terms used across the documents.

-   **Interpretability and Validation**: Using a TDM and traditional PCA might be intended to validate or supplement the insights gained from the kernel PCA. It offers a more straightforward, interpretable view, directly linking principal components to specific words or terms.

-   **Methodological Rigor**: Employing two methodologies can provide a robustness check, ensuring that findings are not artifacts of a particular method but are consistently observable across different analytical approaches.

**Considerations**

-   **Objective Alignment**: Ensure that the analysis method aligns with your research objectives. Kernel PCA might be more suitable if the focus is on uncovering complex patterns and relationships, while traditional PCA is better for direct term importance and variability analysis.

-   **Data Preparation**: For both methods, data preparation is crucial. Ensure that the text is appropriately preprocessed (stemming, stop-word removal, etc.) and that the data subsets used in each analysis are correctly aligned.

-   **Model Interpretation**: Be clear about what each model tells you about the data. Kernel PCA results might require more sophisticated interpretation techniques, whereas traditional PCA results can often be directly interpreted by examining the loadings of principal components.

**Fit & Details**

-   **Individual Tree Predictions**: Each tree in the Random Forest makes predictions based on a subset of the data and a subset of the features (terms). These subsets are randomly selected, ensuring that each tree develops a unique perspective based on different portions of the dataset and different sets of terms.
-   **Error Estimation**: When a tree is grown, it doesn't use all the available features. This allows for something called "out-of-bag" error estimation, where the data not used in training a particular tree (out-of-bag data) are used to test the tree. This process estimates how each feature (term) impacts the prediction error. For each tree, the error increase when a feature is omitted (by permuting the feature values) indicates the importance of that feature.
-   **Aggregation of Predictions**: The Random Forest algorithm aggregates the predictions from all individual trees to form a final prediction. This aggregation is typically a simple majority vote for classification or an average for regression. This step helps to stabilize the predictions by reducing variance without substantially increasing bias.
-   **Feature Importance Accumulation**: Similarly, feature importance – measured by how much the prediction error increases when a feature is left out---are also aggregated across all trees. This aggregation gives a robust estimate of each term's overall importance across the entire model.
-   **Final Interpretation**: The accumulated feature importance values tell us which terms consistently play a significant role in predicting or explaining the principal component scores. Higher importance suggests a term strongly influences the PCA score, providing insights into the themes or patterns that might be driving the variations captured by the PCA.

## Principle Component 1 

### Naive Random Forest 

```{r rand_forest_pc1}
# Fit Random Forest model for 1 Component:
rf_model <- randomForest(as.matrix(dtm_1),
               pc1_scores,
               ntree = 500,
               importance = TRUE)

# Print the model summary to check performance:
print(rf_model)

# Extract importance scores:
importance_scores_pc1 <- importance(rf_model)

# Make a data frame of terms and their importance:
importance_df_pc1 <-
  data.frame(Term = colnames(dtm_1), Importance = importance_scores_pc1[, "%IncMSE"])

# Sort the terms by decreasing importance:
importance_df_pc1 <- importance_df_pc1[order(-importance_df_pc1$Importance), ]

# Display the top important terms:
top_terms <- head(importance_df_pc1, 35)

# Optionally, output results to .csv file:
write.csv(
  importance_df_pc1,
  "./00_documents/visuals/term_importance_PC1.csv",
  row.names = FALSE
)

# import term importance scores 
importance_df_pc1 <- read.csv("00_documents/visuals/term_importance_PC1.csv")
```

```{r}
# display results using datatable 
importance_df_pc1 %>% 
  slice_max(order_by = Importance, n = 35) %>% 
  datatable()
```

### XGB Model Tuning 

```{r}
#| eval: false # skips code execution entirely, comment out to reset 
# Commented out for testing 
# Convert term-document matrix to matrix format
dtm_matrix <- as.matrix(dtm_1)
  
# Convert the response variable to a numeric vector
response_vector <- as.numeric(pc1_scores)
  
# Create an xgb.DMatrix object
dtrain <- xgb.DMatrix(data = dtm_matrix, label = response_vector)
  
param_grid <- expand.grid(
  max_depth = c(4, 6, 8),
  eta = c(0.01, 0.1, 0.3),
  gamma = c(0, 0.1, 0.2),
  colsample_bytree = c(0.6, 0.8, 1),
  min_child_weight = c(1, 3, 5),
  subsample = c(0.6, 0.8, 1),
  nrounds = c(100, 200, 500)
)

# Create cross-validation folds
set.seed(123)
cv_folds <- createFolds(response_vector, k = 3, list = TRUE)

# Function to run cross-validation and return RMSE
cv_rmse <- function(params) {
  cv <- xgb.cv(
    params = params,
    data = dtrain,
    nrounds = params$nrounds,
    folds = cv_folds,
    metrics = "rmse",
    verbose = FALSE
  )
  return(min(cv$evaluation_log$test_rmse_mean))
}

best_params <- NULL
best_rmse <- Inf

for (i in 1:nrow(param_grid)) {
  params <- as.list(param_grid[i, ])
  params$objective <- "reg:squarederror"
  
  rmse <- cv_rmse(params)
  
  if (rmse < best_rmse) {
    best_rmse <- rmse
    best_params <- params
  }
  
  print(paste("Completed iteration", i, "with RMSE:", rmse))
}

print(best_params)
print(paste("Best RMSE:", best_rmse))

final_model <- xgb.train(params = best_params,
                         data = dtrain,
                         nrounds = best_params$nrounds)

# Make predictions (using iteration_range)
preds <- predict(final_model, dtrain, iteration_range = c(1, best_params$nrounds))
```

### XGB Model Results 

```{r}
# # Convert term-document matrix to matrix format
# dtm_matrix_1 <- as.matrix(dtm_1)
# 
# # Convert the response variable to a numeric vector
# response_vector_1 <- as.numeric(pc1_scores)
# 
# # Create an xgb.DMatrix object
# dtrain_1 <- xgb.DMatrix(data = dtm_matrix_1, label = response_vector_1)
# 
# # Set parameters for the XGBoost model
# params_1 <- list(
#   objective = "reg:squarederror", # For regression task
#   max_depth = 6, # Maximum depth of the tree
#   eta = 0.3, # Learning rate
#   nthread = 2, # Number of threads to use
#   eval_metric = "rmse" # Evaluation metric
# )
# 
# # Train the XGBoost model
# xgb_model_1 <- xgb.train(
#   params = params_1,
#   data = dtrain_1,
#   nrounds = 2000 # Number of boosting rounds
# )
# 
# # Get feature importance scores
# importance_scores_1 <- xgb.importance(feature_names = colnames(dtm_matrix_1), model = xgb_model_1)
# 
# # Convert to a data frame
# importance_df_1 <- as.data.frame(importance_scores_1)
# 
# # Sort the terms by decreasing importance
# importance_df_1 <- importance_df_1[order(-importance_df_1$Gain), ]
# 
# # Display the top important terms
# top_terms_1 <- head(importance_df_1, 35)
# print(top_terms_1)
# 
# # Optionally, output results to .csv file:
# write.csv(
#   importance_df_1,
#   "./00_documents/visuals/term_importance_xgboost_PC1.csv",
#   row.names = FALSE
# )

# Load results 
importance_df_1 <- read.csv(  "./00_documents/visuals/term_importance_xgboost_PC1.csv")

# Print xgb results using datatable 
importance_df_1 %>% 
  datatable()
```

## Principle Component 2 

### Naive Random Forest 

```{r rand_forest_pc2}
# Fit the Random Forest model using PC2 scores:
rf_model_pc2 <- randomForest(
  as.matrix(dtm_1),
  pc2_scores,
  ntree = 500,
  maxnodes = 5,
  importance = TRUE
)

# Print the model summary to check performance:
print(rf_model_pc2)

# Extract importance scores:
importance_scores_pc2 <- importance(rf_model_pc2)

# Make a data frame of terms and their importance:
importance_df_pc2 <-
  data.frame(Term = colnames(dtm_1), Importance = importance_scores_pc2[, "%IncMSE"])

# Sort the terms by decreasing importance:
importance_df_pc2 <-
  importance_df_pc2[order(-importance_df_pc2$Importance),]

# Display the top important terms:
top_terms_pc2 <- head(importance_df_pc2, 35)

# Optionally, output results to .csv file:
write.csv(
  importance_df_pc2,
  "./00_documents/visuals/term_importance_PC2.csv",
  row.names = FALSE
)

# Load Results 
importance_df_pc2 <- read.csv(  "./00_documents/visuals/term_importance_PC2.csv",
)


# Print xgb results using datatable 
top_terms_pc2 %>% 
  datatable()
```

### XGB Model Tuning 

```{r}
# Convert term-document matrix to matrix format
# dtm_matrix <- as.matrix(dtm_1)

# Convert the response variable to a numeric vector
# response_vector <- as.numeric(pc2_scores)

# Create an xgb.DMatrix object
# dtrain <- xgb.DMatrix(data = dtm_matrix, label = response_vector)

# param_grid <- expand.grid(
#   max_depth = c(4, 6, 8),
#   eta = c(0.01, 0.1, 0.3),
#   gamma = c(0, 0.1, 0.2),
#   colsample_bytree = c(0.6, 0.8, 1),
#   min_child_weight = c(1, 3, 5),
#   subsample = c(0.6, 0.8, 1),
#   nrounds = c(100, 200, 500)
# )

# Create cross-validation folds
# set.seed(123)
# cv_folds <- createFolds(response_vector, k = 3, list = TRUE)

# Function to run cross-validation and return RMSE
# cv_rmse <- function(params) {
#   cv <- xgb.cv(
#     params = params,
#     data = dtrain,
#     nrounds = params$nrounds,
#     folds = cv_folds,
#     metrics = "rmse",
#     verbose = FALSE
#   )
#   return(min(cv$evaluation_log$test_rmse_mean))
# }
# best_params <- NULL
# best_rmse <- Inf

# for (i in 1:nrow(param_grid)) {
#   params <- as.list(param_grid[i,])
#   params$objective <- "reg:squarederror"
  
#   rmse <- cv_rmse(params)
  
#   if (rmse < best_rmse) {
#     best_rmse <- rmse
#     best_params <- params
#   }
  
#   print(paste("Completed iteration", i, "with RMSE:", rmse))
# }

# print(best_params)
# print(paste("Best RMSE:", best_rmse))

# final_model <- xgb.train(
#   params = best_params,
#   data = dtrain,
#   nrounds = best_params$nrounds
# )

# Make predictions (using iteration_range)
# preds <- predict(final_model, dtrain, iteration_range = c(1, best_params$nrounds))
# preds
```

### XGB Model Results 

```{r}
# Convert term-document matrix to matrix format
dtm_matrix_2 <- as.matrix(dtm_1)

# Convert the response variable to a numeric vector
response_vector_2 <- as.numeric(pc2_scores)

# Create an xgb.DMatrix object
dtrain_2 <- xgb.DMatrix(data = dtm_matrix_2, label = response_vector_2)

# Set parameters for the XGBoost model
params_2 <- list(
  objective = "reg:squarederror",
  max_depth = 5,     # Reduced from  to limit tree depth
  eta = 0.1,         # Changed from 0.3 to 0.1
  nthread = 2,
  eval_metric = "rmse",
  alpha = 1,         # L1 regularization term
  lambda = 1         # L2 regularization term
)

# Train the XGBoost model
xgb_model_2 <- xgb.train(
  params = params_2,
  data = dtrain_2,
  nrounds = 100 # Number of boosting rounds
)

# Get feature importance scores
importance_scores_xgb2 <- xgb.importance(feature_names = colnames(dtm_matrix_2), model = xgb_model_2)

# Convert to a data frame
importance_df_xgb_2 <- as.data.frame(importance_scores_xgb2)

# Sort the terms by decreasing importance
importance_df_xgb_2 <- importance_df_xgb_2[order(-importance_df_xgb_2$Gain), ]

# Display the top important terms
top_terms_xgb_2 <- head(importance_df_xgb_2, 35)

# Optionally, output results to .csv file:
write.csv(
  importance_df_xgb_2,
  "./00_documents/visuals/term_importance_xgboost_PC2.csv",
  row.names = FALSE
)

# Print xgb results using datatable 
top_terms_xgb_2 %>% 
  datatable()
```
### BRF - PC1 Feature Importance 

```{r}
# BRF - PC1 Feature Imporance 

importance_df_pc1$Term <- factor(importance_df_pc1$Term, levels = unique(importance_df_pc1$Term)[order(importance_df_pc1$Importance, decreasing = F)])

# Add a color column: top 5 bars in a different color, rest are light grey
importance_df_pc1 <- importance_df_pc1 %>%
  mutate(color = if_else(row_number(desc(Importance)) <= 10, 'steelblue', 'lightgrey'))

# # Define x-axis settings as before
# xaxis <- list(
#   title = "Increase in MSE",
#   showline = TRUE,
#   showgrid = FALSE,
#   showticklabels = TRUE,
#   linecolor = 'rgb(204, 204, 204)',
#   linewidth = 2,
#   autotick = FALSE,
#   ticks = 'outside',
#   tickcolor = 'rgb(204, 204, 204)',
#   tickwidth = 2,
#   ticklen = 5,
#   tickfont = list(family = 'Arial', size = 12, color = 'rgb(82, 82, 82)')
# )
# 
# # Plot with increased space between ticks and y-axis
# plot_ly(data = importance_df_pc1[1:35,], x = ~ Importance, y = ~ Term, type = 'bar',
#         marker = list(color = ~color)) %>% 
#   layout(
#     title = "<b>PC1 Model Results</b>\nTop Terms",
#     xaxis = xaxis, 
#     yaxis = list(
#       title = "Terms",
#       ticksuffix = "   ",
#       tickfont = list(family = 'Arial', size = 16, color = 'rgb(82, 82, 82)'), # Larger font size for terms
#       tickpadding = 10 # Adjust padding as needed to increase space
#     ), 
#     hovermode = "y unified", 
#     margin = margin_list
#   ) %>% 
#   config(displaylogo = FALSE)

plot_ly(data = importance_df_pc1[1:35,], x = ~Importance, y = ~Term, type = 'bar',
        marker = list(color = ~color)) %>% 
  layout(
    title = list(
      text = paste0("<b>Figure X</b><br><i>PC1 Model Results - Top 35 Terms</i>"),
      x = 0.1, 
      y = -1,
      xanchor = "left", 
      yanchor = "top", 
      font = list(size = 16)
    ),
    #xaxis = xaxis, 
    xaxis = list(title = "<b>Increase in Mean Squared Error</b>",       # X-axis label
                 titlefont = list(size = 14),  # Axis label font size
                 showline = TRUE,
                 linecolor = 'rgb(204, 204, 204)',
                 showgrid = FALSE,
                 showticklabels = TRUE,
                 linecolor = 'rgb(204, 204, 204)',
                 linewidth = 2,
                 autotick = FALSE,
                 ticks = 'outside',
                 tickcolor = 'rgb(204, 204, 204)',
                 tickwidth = 2,
                 ticklen = 5,
                 tickfont = list(family = 'Arial', size = 12, color = 'rgb(82, 82, 82)')
                 ),        
    yaxis = list(
      title = "<b>Term</b>",
      ticksuffix = "   ",
      tickfont = list(family = 'Arial', size = 14, color = 'rgb(82, 82, 82)'), # Larger font size for terms
      tickpadding = 10, # Adjust padding as needed to increase space
      categoryorder = "total ascending" # Ensures all factor levels are shown
    ), 
    
    hovermode = "y unified", 
    # Set Margins 
    margin = list(l = 100, r = 100, t = 150, b = 100)) %>% 
  config(displaylogo = FALSE)


```

### BRF - PC2 Feature Importance 
```{r}
# BRF - PC2 Feature Imporance 

rownames(top_terms_pc2) <- NULL

top_terms_pc2$Term <- factor(top_terms_pc2$Term, levels = unique(top_terms_pc2$Term)[order(top_terms_pc2$Importance, decreasing = F)])

# Add a color column: top 5 bars in a different color, rest are light grey
top_terms_pc2 <- top_terms_pc2 %>%
  mutate(color = if_else(row_number(desc(Importance)) <= 10, 'red', 'lightgrey'))

plot_ly(data = top_terms_pc2[1:35,], x = ~Importance, y = ~Term, type = 'bar',
        marker = list(color = ~color)) %>% 
  layout(
    title = list(
      text = paste0("<b>Figure X</b><br><i>PC2 Model Results - Top 35 Terms</i>"),
      x = 0.1, 
      y = -1,
      xanchor = "left", 
      yanchor = "top", 
      font = list(size = 16)
    ),
    #xaxis = xaxis, 
    xaxis = list(title = "<b>Increase in Mean Squared Error</b>",       # X-axis label
                 titlefont = list(size = 14),  # Axis label font size
                 showline = TRUE,
                 linecolor = 'rgb(204, 204, 204)',
                 showgrid = FALSE,
                 showticklabels = TRUE,
                 linecolor = 'rgb(204, 204, 204)',
                 linewidth = 2,
                 autotick = FALSE,
                 ticks = 'outside',
                 tickcolor = 'rgb(204, 204, 204)',
                 tickwidth = 2,
                 ticklen = 5,
                 tickfont = list(family = 'Arial', size = 12, color = 'rgb(82, 82, 82)')
                 ),        
    yaxis = list(
      title = "<b>Term</b>",
      ticksuffix = "   ",
      tickfont = list(family = 'Arial', size = 14, color = 'rgb(82, 82, 82)'), # Larger font size for terms
      tickpadding = 10, # Adjust padding as needed to increase space
      categoryorder = "total ascending" # Ensures all factor levels are shown
    ), 
    
    hovermode = "y unified", 
    # Set Margins 
    margin = list(l = 100, r = 100, t = 150, b = 100)) %>% 
  config(displaylogo = FALSE)
```


### **BRF Models vs. Prediction – Correlations:**

```{r brf_models_v_predictions_correlations}
# Calculate correlations:
cor_pc1 <- cor(pc1_scores, predict(rf_model))
cor_pc2 <- cor(pc2_scores, predict(rf_model_pc2))

# View the correlations:
print(cor_pc1)
print(cor_pc2)
```
### **Biplot: KPC1 & KPC2**

```{r biplot_kpc1_v_kpc2}
# Load PCA scores
pca_scores_df <- read_csv("./00_documents/visuals/KPCA_scores_comparison.csv")

# Remove the ".txt" extension from the 'Document' column
pca_scores_df <- pca_scores_df %>%
  mutate(Document = str_remove(Document, "\\.txt$"))

# Load treaty metadata
treaty_metadata <- read_csv("./00_documents/01_CAN_spreadsheets/CAN_universe_cases_douglas.csv")

# Clean and prepare dates
treaty_metadata <- treaty_metadata %>%
  mutate(Date = as.Date(str_replace_all(Date, "/", "-"), format = "%Y-%m-%d"))

# Merge PCA scores with metadata based on the Document identifier
pca_merged_df <- pca_scores_df %>%
  left_join(treaty_metadata, by = c("Document" = "Treaty ID"))

# Update the 'Treaty' column using case_when to replace values
pca_merged_df <- pca_merged_df %>%
  dplyr::mutate(Type = gsub("^The Numbered Treaties.*", "The Numbered Treaties", Type))

# Define your custom color palette as a list of hex codes
custom_colors <- c("#EF476F", "#F78C6B", "#FFD166", "#83D483", "#06D6A0", "#0CB0A9", "#118AB2", "#073B4C") # Add more colors as needed

# Create and display the interactive biplot
biplot <- plot_ly(
  data = pca_merged_df,
  x = ~PC1_Score,
  y = ~PC2_Score,
  type = 'scatter',
  mode = 'markers',
  color = ~Type,
  colors = custom_colors,  # Use custom color palette here
  marker = list(size = 10, opacity = 0.8, line = list(width = 1, color = '#FFFFFF')),
  text = ~paste(
    "Treaty Name:", `Treaty Name`,
    "<br>Type:", Type,
    "<br>Date:", Date,
    "<br>PC1 Score:", round(PC1_Score, 3),
    "<br>PC2 Score:", round(PC2_Score, 3)
  ),
  hoverinfo = 'text'
) %>%
  layout(
    title = list(
      text = paste0(
        "<b>Figure X</b>
        <br><i>Biplot of Canadian-Indigenous Treaties</i>"),
      x = 0.1, 
      y = -1,
      xanchor = "left", yanchor = "top", font = list(size = 16)
    ),
    xaxis = list(title = "<b>Principal Component 1 (KPC1)", titlefont = list(size = 14), tickfont = list(size = 12)),
    yaxis = list(title = "<b>Principal Component 2 (KPC2)", titlefont = list(size = 14), tickfont = list(size = 12)),
    legend = list(title = list(text = "Treaty Type", font = list(size = 14)), font = list(size = 12)),
    margin = list(l = 100, r = 100, t = 150, b = 200)
  ) %>% 
  add_annotations(
    text = "<i>Note. High KPC1 indicates a focus on land transactions, property rights, and financial compensation; 
    low KPC1 emphasizes governance, legal administration, and Indigenous relations.
    High KPC2 reflects formal legal language with references to the British Crown;
    low KPC2 denotes practical and informal language.
    ",
    x = 0.5,  # Centered horizontally
    y = -1,  # Position below the graph
    xref = "paper",
    yref = "paper",
    showarrow = FALSE
  )

biplot
# Save the interactive biplot as an HTML file
saveWidget(biplot, "biplot_canadian_indigenous_treaties.html")
```


### **Principal Components Table:**

```{r principle_components_table}
# Load PCA scores
pca_scores_df <- read_csv("./00_documents/visuals/KPCA_scores_comparison.csv")

# Remove the ".txt" extension from the 'Document' column
pca_scores_df <- pca_scores_df %>%
  mutate(Document = str_remove(Document, "\\.txt$"))

# Load treaty metadata
treaty_metadata <- read_csv("./00_documents/01_CAN_spreadsheets/CAN_universe_cases_douglas.csv")

# Clean and prepare dates
treaty_metadata <- treaty_metadata %>%
  mutate(Date = as.Date(str_replace_all(Date, "/", "-"), format = "%Y-%m-%d"))

# Merge PCA scores with metadata based on the Document identifier
pca_merged_df <- pca_scores_df %>%
  left_join(treaty_metadata, by = c("Document" = "Treaty ID"))

# Summarize KPC1 and KPC2 based on descriptions in the subtitle
pca_merged_df <- pca_merged_df %>%
  mutate(
    KPC1_Summary = if_else(PC1_Score > 0, "Land", "Governance"),
    KPC2_Summary = if_else(PC2_Score > 0, "Formal", "Practical")
  )

# Select the columns: Treaty Name, KPC1_Summary, PC1_Score, KPC2_Summary, and PC2_Score
summary_table <- pca_merged_df %>%
  select(`Treaty Name`, KPC1_Summary, PC1_Score, KPC2_Summary, PC2_Score)

# Display the table
summary_table %>% 
  datatable()
```

# Time Trend Analysis

